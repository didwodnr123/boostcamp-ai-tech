{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23b45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9350ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb977a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/opt/ml/input/data/train/images'\n",
    "\n",
    "not_jpg_file = []\n",
    "for (root, dirs, files) in os.walk(root_dir):\n",
    "    if len(files) > 0:\n",
    "        for file_name in files:\n",
    "            t = file_name.split('.')[-1]\n",
    "            if len(t) > 4:\n",
    "                continue\n",
    "\n",
    "            if t != 'jpg' and file_name[0] != '.':\n",
    "                not_jpg_file.append(f'{root}/{file_name}')\n",
    "\n",
    "for imagedir in not_jpg_file:\n",
    "    im = Image.open(imagedir)\n",
    "    im.save(imagedir.split('.')[0] + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddf3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/opt/ml/input/data/eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f55f19a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2be8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000):\n",
    "        super(MyModel, self).__init__()\n",
    "        model = models.vgg19(pretrained=True)\n",
    "        self.features = model.features\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(512,num_classes)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48475e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MyModel(18)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a3c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, img_paths, transform,label):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        self.label = label\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index]).convert('RGB')\n",
    "        # image = np.array(image)\n",
    "        label = self.label[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "206e1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "size=384\n",
    "size2=384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "421cded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_train.csv')\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((size,size2), Image.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "data = Dataset(df['path'],trans,df['class_label'])\n",
    "df2 = pd.read_csv('new_valid.csv')\n",
    "data2=Dataset(df2['path'],trans,df2['class_label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc2d1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64\n",
    "train_dataloader = DataLoader(data, batch_size=bs, shuffle=True)\n",
    "val_dataloader = DataLoader(data2, batch_size=bs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d6743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 19,\n",
    "    'epochs': 30,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-5,\n",
    "    'weight_decay':1e-6,\n",
    "    'num_workers': 2,\n",
    "    'accum_iter': 2, \n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4579b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n",
    "    model.train()\n",
    "\n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "\n",
    "        with autocast():\n",
    "            image_preds = model(imgs)   \n",
    "\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01\n",
    "\n",
    "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
    "\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                if scheduler is not None and schd_batch_update:\n",
    "                    scheduler.step()\n",
    "\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                \n",
    "                pbar.set_description(description)\n",
    "                \n",
    "    if scheduler is not None and not schd_batch_update:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6347c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        image_preds = model(imgs)   \n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]  \n",
    "\n",
    "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
    "            description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "            pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    print('validation multi-class f1_score = {:.4f}'.format(f1_score(image_preds_all,image_targets_all,average='macro')))\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        if schd_loss_update:\n",
    "            scheduler.step(loss_sum/sample_num)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "    \n",
    "    return f1_score(image_preds_all,image_targets_all,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8739c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()   \n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=2, eta_min=CFG['min_lr'], last_epoch=-1)\n",
    "\n",
    "loss_tr = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cedc2c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.8087: 100%|██████████| 248/248 [04:14<00:00,  1.03s/it]\n",
      "epoch 0 loss: 0.3543: 100%|██████████| 31/31 [00:55<00:00,  1.79s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.6829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.2827: 100%|██████████| 248/248 [03:40<00:00,  1.12it/s]\n",
      "epoch 1 loss: 0.3900: 100%|██████████| 31/31 [00:45<00:00,  1.47s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.1522: 100%|██████████| 248/248 [03:41<00:00,  1.12it/s]\n",
      "epoch 2 loss: 0.3585: 100%|██████████| 31/31 [00:45<00:00,  1.45s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.7482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.0935: 100%|██████████| 248/248 [03:39<00:00,  1.13it/s]\n",
      "epoch 3 loss: 0.4023: 100%|██████████| 31/31 [00:44<00:00,  1.45s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.7785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.0406: 100%|██████████| 248/248 [03:39<00:00,  1.13it/s]\n",
      "epoch 4 loss: 0.5292: 100%|██████████| 31/31 [00:44<00:00,  1.43s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.7817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.0203: 100%|██████████| 248/248 [03:38<00:00,  1.13it/s]\n",
      "epoch 5 loss: 0.5769: 100%|██████████| 31/31 [00:45<00:00,  1.45s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.7933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.0122: 100%|██████████| 248/248 [03:37<00:00,  1.14it/s]\n",
      "epoch 6 loss: 0.5450: 100%|██████████| 31/31 [00:45<00:00,  1.46s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.8020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.0045: 100%|██████████| 248/248 [03:40<00:00,  1.13it/s]\n",
      "epoch 7 loss: 0.7490: 100%|██████████| 31/31 [00:45<00:00,  1.47s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.8039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.0039: 100%|██████████| 248/248 [03:38<00:00,  1.14it/s]\n",
      "epoch 8 loss: 0.6631: 100%|██████████| 31/31 [00:44<00:00,  1.45s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.8059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.0027: 100%|██████████| 248/248 [03:36<00:00,  1.14it/s]\n",
      "epoch 9 loss: 0.6996: 100%|██████████| 31/31 [00:45<00:00,  1.47s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.7982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10 loss: 0.1253: 100%|██████████| 248/248 [03:37<00:00,  1.14it/s]\n",
      "epoch 10 loss: 0.3968: 100%|██████████| 31/31 [00:45<00:00,  1.46s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.7739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11 loss: 0.0446: 100%|██████████| 248/248 [03:37<00:00,  1.14it/s]\n",
      "epoch 11 loss: 0.5445: 100%|██████████| 31/31 [00:44<00:00,  1.42s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.7787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12 loss: 0.0214: 100%|██████████| 248/248 [03:37<00:00,  1.14it/s]\n",
      "epoch 12 loss: 0.5644: 100%|██████████| 31/31 [00:44<00:00,  1.45s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.7803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13 loss: 0.0297: 100%|██████████| 248/248 [03:37<00:00,  1.14it/s]\n",
      "epoch 13 loss: 0.5952: 100%|██████████| 31/31 [00:44<00:00,  1.44s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.8031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14 loss: 0.0125: 100%|██████████| 248/248 [03:38<00:00,  1.14it/s]\n",
      "epoch 14 loss: 0.5162: 100%|██████████| 31/31 [00:44<00:00,  1.44s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.8145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15 loss: 0.0066: 100%|██████████| 248/248 [03:36<00:00,  1.14it/s]\n",
      "epoch 15 loss: 0.5714: 100%|██████████| 31/31 [00:44<00:00,  1.44s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.8039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16 loss: 0.0023: 100%|██████████| 248/248 [03:38<00:00,  1.13it/s]\n",
      "epoch 16 loss: 0.6698: 100%|██████████| 31/31 [00:44<00:00,  1.43s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.7959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17 loss: 0.0011: 100%|██████████| 248/248 [03:38<00:00,  1.13it/s]\n",
      "epoch 17 loss: 0.6812: 100%|██████████| 31/31 [00:44<00:00,  1.45s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.8070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18 loss: 0.0029: 100%|██████████| 248/248 [03:39<00:00,  1.13it/s]\n",
      "epoch 18 loss: 0.6738: 100%|██████████| 31/31 [00:45<00:00,  1.45s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.8152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19 loss: 0.0007: 100%|██████████| 248/248 [03:36<00:00,  1.14it/s]\n",
      "epoch 19 loss: 0.7278: 100%|██████████| 31/31 [00:45<00:00,  1.45s/it]\n",
      "  0%|          | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class f1_score = 0.8033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 20 loss: 0.0005: 100%|██████████| 248/248 [03:37<00:00,  1.14it/s]\n",
      "epoch 20 loss: 0.7487:  16%|█▌        | 5/31 [00:08<00:46,  1.79s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7376cb5be63f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mvalid_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschd_loss_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mfolder_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weight'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/{}_fold_{}_{}.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vgg19'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_f1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-5909b0b51b1f>\u001b[0m in \u001b[0;36mvalid_one_epoch\u001b[0;34m(epoch, model, loss_fn, val_loader, device, scheduler, schd_loss_update)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimage_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mimage_preds_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mimage_targets_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(CFG['epochs']):\n",
    "    train_one_epoch(epoch, model, loss_tr, optimizer, train_dataloader, device, scheduler=scheduler, schd_batch_update=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        valid_f1 = valid_one_epoch(epoch, model, loss_fn, val_dataloader, device, scheduler=None, schd_loss_update=False)\n",
    "    folder_name = ''\n",
    "    torch.save(model.state_dict(), folder_name+'/{}_fold_{}_{}.pt'.format('vgg19', epoch,np.round(valid_f1,3)))\n",
    "# del optimizer, train_dataloader, val_dataloader, scaler, scheduler\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
