{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"4_Model.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"}},"cells":[{"cell_type":"markdown","source":["## Lesson 5 - Model\n"," - 이번 실습 자료에서는 강의시간에 다루었던 파이토치 모델을 정의하는 방법에 대해 실습하겠습니다.\n"," - 파이토치 모델은 기본적으로 `nn.Module` 클래스를 상속하여 사용합니다.\n","     - [공식문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)에 따르면 `nn.Module` 은 다음과 같은 기능을 합니다\n","     ```\n","     Base class for all neural network modules.\n","     Your models should also subclass this class.\n","     Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes:\n","     ```"],"metadata":{"id":"UmDju1hmS-__"}},{"cell_type":"code","execution_count":1,"source":["from pprint import pprint\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"outputs":[],"metadata":{"id":"zCROkRzlS-_7"}},{"cell_type":"code","execution_count":2,"source":["class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, bias=True)\n","        self.bn1 = nn.BatchNorm2d(num_features=3)\n","        self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, bias=False)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        return F.relu(self.conv2(x))"],"outputs":[],"metadata":{"id":"toANDtC5S_AA"}},{"cell_type":"code","execution_count":3,"source":["model = Model()\n","model"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n","  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",")"]},"metadata":{},"execution_count":3}],"metadata":{"id":"uWxGW2iyS_AB"}},{"cell_type":"markdown","source":["### 모델 디버깅\n"," - 파이토치 모델들은 다음과 같읕 방법들을 통해 파라미터를 눈으로 확인할 수 있습니다."],"metadata":{"id":"NtmySw1gS_AC"}},{"cell_type":"code","execution_count":4,"source":["# 1. named_parameters() 를 이용하는 방식\n","for param, weight in model.named_parameters():\n","    print(f\"{param:20} - size: {weight.size()}\")\n","    print(weight)\n","    print(\"-\" * 100)\n","    print()"],"outputs":[{"output_type":"stream","name":"stdout","text":["conv1.weight         - size: torch.Size([3, 1, 3, 3])\n","Parameter containing:\n","tensor([[[[ 0.0632,  0.0816, -0.1601],\n","          [-0.0782,  0.2738, -0.1451],\n","          [ 0.2739, -0.2237,  0.3006]]],\n","\n","\n","        [[[ 0.1469,  0.2954,  0.1358],\n","          [-0.1137, -0.2717, -0.1300],\n","          [-0.0135, -0.0384,  0.2190]]],\n","\n","\n","        [[[-0.1787, -0.3220, -0.1830],\n","          [-0.1672, -0.1014, -0.2990],\n","          [-0.1132, -0.1924, -0.0353]]]], requires_grad=True)\n","----------------------------------------------------------------------------------------------------\n","\n","conv1.bias           - size: torch.Size([3])\n","Parameter containing:\n","tensor([-0.2789,  0.2299,  0.0031], requires_grad=True)\n","----------------------------------------------------------------------------------------------------\n","\n","bn1.weight           - size: torch.Size([3])\n","Parameter containing:\n","tensor([1., 1., 1.], requires_grad=True)\n","----------------------------------------------------------------------------------------------------\n","\n","bn1.bias             - size: torch.Size([3])\n","Parameter containing:\n","tensor([0., 0., 0.], requires_grad=True)\n","----------------------------------------------------------------------------------------------------\n","\n","conv2.weight         - size: torch.Size([5, 3, 3, 3])\n","Parameter containing:\n","tensor([[[[ 0.0377,  0.1776,  0.1166],\n","          [ 0.0919, -0.1871, -0.0313],\n","          [-0.1408, -0.1381, -0.0889]],\n","\n","         [[ 0.0858,  0.1048,  0.0196],\n","          [-0.0009,  0.1837, -0.0941],\n","          [-0.1133, -0.1495,  0.1023]],\n","\n","         [[ 0.1098,  0.1643, -0.1224],\n","          [-0.1118,  0.0915, -0.0653],\n","          [ 0.0630,  0.0489, -0.1387]]],\n","\n","\n","        [[[-0.1020,  0.1161,  0.1769],\n","          [ 0.1105, -0.0816, -0.1226],\n","          [-0.0431, -0.0438,  0.0586]],\n","\n","         [[ 0.1468,  0.1670,  0.1626],\n","          [-0.0305, -0.0420,  0.1294],\n","          [ 0.0178,  0.1623,  0.0764]],\n","\n","         [[ 0.0887,  0.0306,  0.0871],\n","          [ 0.0858,  0.0749, -0.0431],\n","          [ 0.1491,  0.0841, -0.0832]]],\n","\n","\n","        [[[ 0.1893,  0.1832,  0.0453],\n","          [ 0.1787, -0.0558, -0.0581],\n","          [ 0.0314, -0.0819,  0.1618]],\n","\n","         [[-0.0762, -0.0948, -0.0219],\n","          [-0.0586, -0.0628, -0.1172],\n","          [ 0.1755,  0.0773,  0.1908]],\n","\n","         [[ 0.0561, -0.1543, -0.0051],\n","          [ 0.0907,  0.1259,  0.1138],\n","          [ 0.1439,  0.1273, -0.1631]]],\n","\n","\n","        [[[-0.0019, -0.0609, -0.1778],\n","          [-0.1711, -0.1505,  0.0884],\n","          [-0.1176, -0.0346,  0.1408]],\n","\n","         [[ 0.1621,  0.1276,  0.1329],\n","          [ 0.1244, -0.0584, -0.1566],\n","          [-0.0582, -0.0484,  0.0864]],\n","\n","         [[ 0.1062,  0.1244,  0.0304],\n","          [-0.0982, -0.0878,  0.1399],\n","          [-0.1497,  0.0748,  0.1065]]],\n","\n","\n","        [[[-0.1803, -0.0099, -0.0679],\n","          [ 0.0170,  0.0909,  0.0763],\n","          [-0.1189,  0.1781, -0.1639]],\n","\n","         [[-0.0740, -0.0787, -0.1359],\n","          [-0.0719, -0.0700, -0.0860],\n","          [-0.1404,  0.1841,  0.1517]],\n","\n","         [[ 0.1408, -0.1533, -0.1843],\n","          [ 0.0692,  0.1018, -0.1202],\n","          [-0.1489,  0.0968, -0.0746]]]], requires_grad=True)\n","----------------------------------------------------------------------------------------------------\n","\n"]}],"metadata":{"scrolled":true,"id":"sX8A26RhS_AD"}},{"cell_type":"code","execution_count":5,"source":["# 2. 멤버 변수를 이용하여 직접 access 하는 방법\n","print(model.conv1.weight)\n","print(model.conv1.bias)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[[[ 0.0632,  0.0816, -0.1601],\n","          [-0.0782,  0.2738, -0.1451],\n","          [ 0.2739, -0.2237,  0.3006]]],\n","\n","\n","        [[[ 0.1469,  0.2954,  0.1358],\n","          [-0.1137, -0.2717, -0.1300],\n","          [-0.0135, -0.0384,  0.2190]]],\n","\n","\n","        [[[-0.1787, -0.3220, -0.1830],\n","          [-0.1672, -0.1014, -0.2990],\n","          [-0.1132, -0.1924, -0.0353]]]], requires_grad=True)\n","Parameter containing:\n","tensor([-0.2789,  0.2299,  0.0031], requires_grad=True)\n"]}],"metadata":{"id":"RGOd8u6NS_AD"}},{"cell_type":"markdown","source":["### 학습된 모델 저장하기\n"," - `torch.save(model.state_dict(), save_path)`"],"metadata":{"id":"PV5CYMXRS_AE"}},{"cell_type":"code","execution_count":6,"source":["import os\n","\n","save_folder = \"./runs/\"\n","save_path = os.path.join(save_folder, \"best.pth\")   # ./runs/best.pth\n","os.makedirs(save_folder, exist_ok=True)  \n","\n","torch.save(model.state_dict(), save_path)\n","print(f\"{save_path} 폴더에 모델이 성공적으로 저장되었습니다.\")\n","print(f\"해당 폴더의 파일 리스트: {os.listdir(save_folder)}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["./runs/best.pth 폴더에 모델이 성공적으로 저장되었습니다.\n","해당 폴더의 파일 리스트: ['best.pth']\n"]}],"metadata":{"id":"Cq8GYbN1S_AF"}},{"cell_type":"markdown","source":["### 저장된 모델 불러오기\n"," - model.load_state_dict(torch.load(save_path))"],"metadata":{"id":"BqwVdTsKS_AF"}},{"cell_type":"code","execution_count":7,"source":["new_model = Model()\n","new_model.load_state_dict(torch.load(save_path))\n","print(f\"{save_path} 에서 성공적으로 모델을 load 하였습니다.\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["./runs/best.pth 에서 성공적으로 모델을 load 하였습니다.\n"]}],"metadata":{"id":"bZ4UN19tS_AG"}},{"cell_type":"markdown","source":["#### 저장된 모델이 잘 불러와졌는지 확인해봅시다"],"metadata":{"id":"WZn5x9SdS_AG"}},{"cell_type":"code","execution_count":8,"source":["for (name, trained_weight), (_, saved_weight) in zip(model.named_parameters(), new_model.named_parameters()):\n","    is_equal = torch.equal(trained_weight, saved_weight)\n","    print(f\"파라미터 {name:15} 에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> {is_equal}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["파라미터 conv1.weight    에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n","파라미터 conv1.bias      에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n","파라미터 bn1.weight      에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n","파라미터 bn1.bias        에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n","파라미터 conv2.weight    에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n"]}],"metadata":{"id":"qRYRythjS_AH"}},{"cell_type":"markdown","source":["#### state_dict() 이 무엇인가요?\n"," - 모델의 저장과 로딩에 `state_dict()` 을 사용하는데, 기능이 무엇인가요?\n"," - 기본적으로 위에서 살펴본 `.named_parameters()` 와 매우 유사합니다\n"," - model parameter 를 Key 로 가지고, model weights 를 Value 로 가지는 파이썬 딕셔너리일 뿐입니다. \n","   (정확한 Type 은 파이썬 내장 라이브러리 collections.OrderDict 입니다)"],"metadata":{"id":"z9JD_kYqS_AH"}},{"cell_type":"code","execution_count":9,"source":["for param, weight in model.state_dict().items():\n","    print(f\"파라미터 네임 {param:25} / 사이즈: {weight.size()}\")\n","    print(weight)\n","    print(\"-\" * 100, end=\"\\n\\n\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["파라미터 네임 conv1.weight              / 사이즈: torch.Size([3, 1, 3, 3])\n","tensor([[[[ 0.0632,  0.0816, -0.1601],\n","          [-0.0782,  0.2738, -0.1451],\n","          [ 0.2739, -0.2237,  0.3006]]],\n","\n","\n","        [[[ 0.1469,  0.2954,  0.1358],\n","          [-0.1137, -0.2717, -0.1300],\n","          [-0.0135, -0.0384,  0.2190]]],\n","\n","\n","        [[[-0.1787, -0.3220, -0.1830],\n","          [-0.1672, -0.1014, -0.2990],\n","          [-0.1132, -0.1924, -0.0353]]]])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 conv1.bias                / 사이즈: torch.Size([3])\n","tensor([-0.2789,  0.2299,  0.0031])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 bn1.weight                / 사이즈: torch.Size([3])\n","tensor([1., 1., 1.])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 bn1.bias                  / 사이즈: torch.Size([3])\n","tensor([0., 0., 0.])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 bn1.running_mean          / 사이즈: torch.Size([3])\n","tensor([0., 0., 0.])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 bn1.running_var           / 사이즈: torch.Size([3])\n","tensor([1., 1., 1.])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 bn1.num_batches_tracked   / 사이즈: torch.Size([])\n","tensor(0)\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 conv2.weight              / 사이즈: torch.Size([5, 3, 3, 3])\n","tensor([[[[ 0.0377,  0.1776,  0.1166],\n","          [ 0.0919, -0.1871, -0.0313],\n","          [-0.1408, -0.1381, -0.0889]],\n","\n","         [[ 0.0858,  0.1048,  0.0196],\n","          [-0.0009,  0.1837, -0.0941],\n","          [-0.1133, -0.1495,  0.1023]],\n","\n","         [[ 0.1098,  0.1643, -0.1224],\n","          [-0.1118,  0.0915, -0.0653],\n","          [ 0.0630,  0.0489, -0.1387]]],\n","\n","\n","        [[[-0.1020,  0.1161,  0.1769],\n","          [ 0.1105, -0.0816, -0.1226],\n","          [-0.0431, -0.0438,  0.0586]],\n","\n","         [[ 0.1468,  0.1670,  0.1626],\n","          [-0.0305, -0.0420,  0.1294],\n","          [ 0.0178,  0.1623,  0.0764]],\n","\n","         [[ 0.0887,  0.0306,  0.0871],\n","          [ 0.0858,  0.0749, -0.0431],\n","          [ 0.1491,  0.0841, -0.0832]]],\n","\n","\n","        [[[ 0.1893,  0.1832,  0.0453],\n","          [ 0.1787, -0.0558, -0.0581],\n","          [ 0.0314, -0.0819,  0.1618]],\n","\n","         [[-0.0762, -0.0948, -0.0219],\n","          [-0.0586, -0.0628, -0.1172],\n","          [ 0.1755,  0.0773,  0.1908]],\n","\n","         [[ 0.0561, -0.1543, -0.0051],\n","          [ 0.0907,  0.1259,  0.1138],\n","          [ 0.1439,  0.1273, -0.1631]]],\n","\n","\n","        [[[-0.0019, -0.0609, -0.1778],\n","          [-0.1711, -0.1505,  0.0884],\n","          [-0.1176, -0.0346,  0.1408]],\n","\n","         [[ 0.1621,  0.1276,  0.1329],\n","          [ 0.1244, -0.0584, -0.1566],\n","          [-0.0582, -0.0484,  0.0864]],\n","\n","         [[ 0.1062,  0.1244,  0.0304],\n","          [-0.0982, -0.0878,  0.1399],\n","          [-0.1497,  0.0748,  0.1065]]],\n","\n","\n","        [[[-0.1803, -0.0099, -0.0679],\n","          [ 0.0170,  0.0909,  0.0763],\n","          [-0.1189,  0.1781, -0.1639]],\n","\n","         [[-0.0740, -0.0787, -0.1359],\n","          [-0.0719, -0.0700, -0.0860],\n","          [-0.1404,  0.1841,  0.1517]],\n","\n","         [[ 0.1408, -0.1533, -0.1843],\n","          [ 0.0692,  0.1018, -0.1202],\n","          [-0.1489,  0.0968, -0.0746]]]])\n","----------------------------------------------------------------------------------------------------\n","\n"]}],"metadata":{"scrolled":false,"id":"0yKFEBJTS_AH"}},{"cell_type":"code","execution_count":10,"source":["from collections import OrderedDict\n","print(f\"model.state_dict() 의 Type : {type(model.state_dict())}\")\n","isinstance(model.state_dict(), OrderedDict)"],"outputs":[{"output_type":"stream","name":"stdout","text":["model.state_dict() 의 Type : <class 'collections.OrderedDict'>\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}],"metadata":{"id":"Ed5j0w3rS_AI"}},{"cell_type":"markdown","source":["#### `named_parameters()` 을 안쓰고 `state_dict()` 을 사용하는 이유가 무언인가요? (둘이 뭐가 다른가요)\n"," - `named_parameters()` : returns only parameters\n"," - `state_dict()`: returns both parameters and buffers (e.g. BN runnin_mean, running_var)\n"," \n"," [Reference](https://stackoverflow.com/a/54747245)"],"metadata":{"id":"aoJVB7XUS_AI"}},{"cell_type":"code","execution_count":11,"source":["pprint([name for (name, param) in model.named_parameters()])  # named_parameters() : returns only parameters\n","print()\n","pprint(list(model.state_dict().keys()))                       # state_dict(): retuns both parameters and buffers"],"outputs":[{"output_type":"stream","name":"stdout","text":["['conv1.weight', 'conv1.bias', 'bn1.weight', 'bn1.bias', 'conv2.weight']\n","\n","['conv1.weight',\n"," 'conv1.bias',\n"," 'bn1.weight',\n"," 'bn1.bias',\n"," 'bn1.running_mean',\n"," 'bn1.running_var',\n"," 'bn1.num_batches_tracked',\n"," 'conv2.weight']\n"]}],"metadata":{"id":"rKBfbJJYS_AJ"}},{"cell_type":"markdown","source":["### CPU vs GPU\n"," - Pytorch 텐서(데이터)는 다양한 프로세서(CPU, GPU, TPU) 에서 연산 및 학습이 가능합니다.\n"," - 따라서, 특정 프로세서에서 학습을 진행하고 싶은 경우 해당 프로세스를 명시적으로 지정해주어야 합니다.\n"," - 이는 해당 텐서(데이터)를 특정 프로세스의 메모리에 load 또는 해당 프로세스의 메모리로 이동하는 것을 의미합니다.\n"," - 따라서, 연산하는 텐서들의 디바이스가 같아야만 연산이 가능합니다. 그렇지 않을 경우 에러가 발생합니다."],"metadata":{"id":"vZBCDWBfS_AJ"}},{"cell_type":"markdown","source":["#### 새로운 텐서 생성"],"metadata":{"id":"mmCL_sXES_AK"}},{"cell_type":"code","execution_count":12,"source":["data = torch.randn(2,2, device=torch.device('cpu'))     # CPU 에 새로운 텐서 생성\n","print(f\"데이터 디바이스: {data.device}\")\n","\n","data = torch.randn(2,2, device=torch.device('cuda:0'))  # GPU 0번에 새로운 텐서 생성\n","print(f\"데이터 디바이스: {data.device}\")\n","\n","data = torch.randn(2,2)                                 # device 를 따로 지정하지 않으면 default 로 CPU 에 생성됩니다.\n","print(f\"데이터 디바이스: {data.device}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 디바이스: cpu\n","데이터 디바이스: cuda:0\n","데이터 디바이스: cpu\n"]}],"metadata":{"id":"I_EH9jgOS_AK"}},{"cell_type":"markdown","source":["#### 이미 생성되어 있는 텐서를 다른 프로세스의 메모리로 이동하는 것도 가능합니다\n","#### .cpu()\n","모든 모델의 파라미터와 버터를 CPU 메모리로 이동"],"metadata":{"id":"FcA2NEVmS_AK"}},{"cell_type":"code","execution_count":13,"source":["model.cpu()\n","for weight in model.parameters():\n","    print(f\"파라미터 디바이스: {weight.device}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n"]}],"metadata":{"id":"c8R3ygRRS_AL"}},{"cell_type":"markdown","source":["#### .cuda()\n","모든 모델의 파라미터와 버터를 GPU 메모리로 이동"],"metadata":{"id":"GobjlWa6S_AL"}},{"cell_type":"code","execution_count":14,"source":["model.cuda()\n","for weight in model.parameters():\n","    print(f\"파라미터 디바이스: {weight.device}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n"]}],"metadata":{"id":"Knj_icpAS_AL"}},{"cell_type":"markdown","source":["#### .to()\n","파라미터 또는 버퍼 메모리를 다음 프로세스로 이동"],"metadata":{"id":"qwOb6ccTS_AM"}},{"cell_type":"code","execution_count":15,"source":["device_options = ['cpu', 'cuda']\n","for device_option in device_options:\n","    device = torch.device(device_option)\n","    model.to(device)\n","    \n","    print(f\"파라미터 디바이스를 {device_option} 로 변경\")\n","    for weight in model.parameters():\n","        print(f\"파라미터 디바이스: {weight.device}\")\n","    print()"],"outputs":[{"output_type":"stream","name":"stdout","text":["파라미터 디바이스를 cpu 로 변경\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","\n","파라미터 디바이스를 cuda 로 변경\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","\n"]}],"metadata":{"id":"pEOar6EWS_AM"}},{"cell_type":"markdown","source":["#### Cautions\n","\n","새로운 텐서를 GPU 에 생성하고 싶은 경우 `torch.randn(2,2).cuda()` 처럼 생성하면\n","\n","1) CPU 메모리에 텐서를 생성 2) CPU -> GPU 메모리로 값을 이동하는 과정이 일어나면서 cost efficient 하지 못합니다\n","\n","`torch.randn(2,2, device=torch.device('cuda:0'))` 와 같이 처음부터 GPU 메모리에 생성하는 것을 권장합니다."],"metadata":{"id":"l1ve5Ky2S_AN"}},{"cell_type":"markdown","source":["#### Cautions\n"," - 연산하는 두 개의 텐서는 반드시 같은 device 에 존재하여야 합니다.\n"," - 그렇지 않으면 에러가 발생합니다."],"metadata":{"id":"bq7KXuyfS_AN"}},{"cell_type":"code","execution_count":16,"source":["data1 = torch.randn(2,2, device=torch.device('cpu'))\n","data2 = torch.randn(2,2, device=torch.device('cpu'))\n","print(data1 + data2)  # 두 텐서가 같은 device(CPU) 에 있기에 연산이 가능합니다."],"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-1.3222, -0.3643],\n","        [ 1.4666,  0.7698]])\n"]}],"metadata":{"id":"2LjfibL_S_AN"}},{"cell_type":"code","execution_count":17,"source":["data1 = torch.randn(2,2, device=torch.device('cpu'))\n","data2 = torch.randn(2,2, device=torch.device('cuda'))\n","print(data1 + data2)  # 두 텐서가 다른 device(CPU, GPU) 에 있기에 연산이 불가능합니다."],"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-243f39335071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 두 텐서가 다른 device(CPU, GPU) 에 있기에 연산이 불가능합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"]}],"metadata":{"id":"KpDpGzCqS_AO"}},{"cell_type":"markdown","source":["### forward\n"," - nn.Module 을 상속한 객체를 직접 호출할 때 수행하는 연산을 정의합니다.\n"," - `model(input)` 을 통해 모델의 예측값을 계산할 수 있습니다.\n"," - Defines the computation performed at every call"],"metadata":{"id":"wcvHa8G5S_AO"}},{"cell_type":"code","execution_count":18,"source":["dummy_input = torch.randn(1, 1, 12, 12, device=device)\n","model.to(device)\n","output = model(dummy_input)\n","print(f\"모델 output 사이즈: {output.size()}\")\n","print(output)"],"outputs":[{"output_type":"stream","name":"stdout","text":["모델 output 사이즈: torch.Size([1, 5, 8, 8])\n","tensor([[[[0.0000e+00, 2.7823e-02, 4.2672e-01, 0.0000e+00, 0.0000e+00,\n","           3.3528e-01, 0.0000e+00, 0.0000e+00],\n","          [2.5449e-01, 1.9834e-01, 1.0132e-01, 5.4044e-01, 6.9005e-01,\n","           6.6063e-02, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 3.2458e-02, 0.0000e+00, 2.3034e-01, 0.0000e+00,\n","           0.0000e+00, 1.5518e-01, 0.0000e+00],\n","          [7.3875e-02, 0.0000e+00, 2.6943e-02, 0.0000e+00, 2.6192e-01,\n","           5.0221e-01, 3.4732e-01, 0.0000e+00],\n","          [2.8412e-01, 2.2574e-01, 0.0000e+00, 9.7654e-02, 4.2375e-01,\n","           1.9148e-01, 0.0000e+00, 0.0000e+00],\n","          [3.3948e-01, 4.6495e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00, 4.3884e-01, 0.0000e+00],\n","          [5.0339e-01, 1.7068e-01, 5.5063e-02, 1.8594e-01, 0.0000e+00,\n","           3.0537e-01, 9.8660e-02, 0.0000e+00],\n","          [0.0000e+00, 2.3381e-01, 1.7807e-01, 0.0000e+00, 4.8889e-01,\n","           2.3553e-01, 9.6920e-02, 4.2213e-01]],\n","\n","         [[3.6168e-02, 7.0818e-01, 6.6615e-01, 6.7678e-01, 3.5419e-01,\n","           0.0000e+00, 0.0000e+00, 9.3891e-02],\n","          [1.6749e-01, 3.3917e-01, 5.1981e-01, 2.6758e-01, 7.3329e-01,\n","           9.6082e-01, 9.5168e-01, 1.9151e-01],\n","          [4.5875e-01, 4.1709e-01, 5.6998e-01, 6.0636e-01, 9.9495e-01,\n","           5.2588e-01, 0.0000e+00, 0.0000e+00],\n","          [3.5471e-01, 3.6183e-01, 2.6461e-01, 2.4851e-01, 4.7464e-01,\n","           8.6642e-01, 6.8762e-01, 6.8373e-01],\n","          [1.1592e+00, 1.1079e+00, 4.3544e-01, 9.2773e-01, 1.0318e+00,\n","           9.4507e-01, 7.8222e-01, 3.1958e-01],\n","          [8.0917e-01, 8.5755e-01, 4.2255e-01, 2.9574e-01, 6.8230e-01,\n","           4.5290e-01, 2.0404e-01, 3.0358e-01],\n","          [5.1235e-01, 8.4158e-01, 8.1922e-01, 1.7355e-01, 6.2565e-01,\n","           1.3317e+00, 7.4040e-01, 3.9077e-01],\n","          [4.5547e-01, 5.3187e-01, 3.8953e-01, 1.1056e+00, 4.8558e-01,\n","           2.2007e-01, 8.5907e-01, 3.4533e-01]],\n","\n","         [[0.0000e+00, 6.1199e-01, 5.0821e-01, 6.4629e-01, 1.5631e-01,\n","           1.7749e-01, 0.0000e+00, 0.0000e+00],\n","          [3.1295e-01, 4.9750e-01, 1.8249e-01, 8.7211e-02, 5.6453e-01,\n","           6.3456e-01, 9.2660e-01, 9.4233e-01],\n","          [9.4877e-01, 5.9857e-02, 6.4510e-01, 5.1983e-01, 1.3942e-01,\n","           3.2371e-01, 3.6450e-01, 0.0000e+00],\n","          [6.4221e-01, 3.1859e-01, 4.0278e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00, 0.0000e+00, 1.8150e-01],\n","          [1.2142e+00, 1.1023e+00, 6.7773e-01, 3.8746e-01, 8.6559e-01,\n","           5.4396e-01, 4.9483e-01, 5.9184e-01],\n","          [3.5847e-01, 8.2191e-01, 4.6065e-01, 7.9123e-01, 2.8659e-01,\n","           2.3488e-01, 3.0415e-01, 1.7032e-01],\n","          [3.4385e-01, 1.6525e-01, 1.3749e-01, 3.0101e-01, 7.3086e-01,\n","           5.5170e-01, 1.7884e-02, 0.0000e+00],\n","          [3.0697e-01, 3.9978e-01, 3.5450e-01, 3.7955e-01, 5.5427e-01,\n","           6.8736e-01, 4.6162e-01, 4.7307e-01]],\n","\n","         [[0.0000e+00, 0.0000e+00, 1.3548e-01, 0.0000e+00, 0.0000e+00,\n","           5.8758e-03, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2212e-03, 7.6512e-01,\n","           1.6062e-01, 0.0000e+00, 4.2548e-01],\n","          [0.0000e+00, 1.4392e-01, 8.6751e-04, 4.8990e-01, 0.0000e+00,\n","           0.0000e+00, 2.0243e-01, 1.8580e-01],\n","          [5.5715e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           6.8060e-01, 9.0482e-01, 5.7154e-01],\n","          [0.0000e+00, 0.0000e+00, 2.0455e-01, 4.3577e-02, 2.5380e-01,\n","           5.7206e-01, 0.0000e+00, 0.0000e+00],\n","          [3.2488e-02, 8.6862e-02, 3.3020e-01, 1.4490e-03, 0.0000e+00,\n","           0.0000e+00, 2.7910e-01, 4.6369e-01],\n","          [7.4474e-01, 1.8813e-01, 0.0000e+00, 5.8579e-01, 0.0000e+00,\n","           7.6740e-02, 2.6794e-01, 2.8387e-01],\n","          [0.0000e+00, 4.5365e-01, 5.3259e-01, 0.0000e+00, 3.0591e-01,\n","           0.0000e+00, 0.0000e+00, 4.7032e-01]],\n","\n","         [[1.3524e-01, 0.0000e+00, 0.0000e+00, 1.7624e-01, 0.0000e+00,\n","           2.4047e-02, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2228e-01,\n","           4.3117e-01, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 1.6008e-01, 0.0000e+00, 2.6803e-01, 2.3958e-01,\n","           0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [9.0572e-02, 0.0000e+00, 1.1632e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2670e-01, 0.0000e+00,\n","           5.0000e-01, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 5.7164e-02, 0.0000e+00, 0.0000e+00, 7.2472e-01,\n","           0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           5.3088e-02, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00, 0.0000e+00, 0.0000e+00]]]], device='cuda:0',\n","       grad_fn=<ReluBackward0>)\n"]}],"metadata":{"scrolled":true,"id":"UXQuTb-4S_AO"}},{"cell_type":"markdown","source":["#### Cautions\n"," - 위에서 말씀드린 것과 같은 원리로 모델과 인풋의 device 는 반드시 같아야 합니다."],"metadata":{"id":"IrbF9fD9S_AP"}},{"cell_type":"code","execution_count":19,"source":["cpu_device = torch.device('cpu')\n","gpu_device = torch.device('cuda')\n","\n","# device is same\n","dummy_input = dummy_input.to(gpu_device)\n","model.to(gpu_device)\n","output = model(dummy_input)  # 잘 작동합니다 \n","print(f\"모델 ouput 사이즈: {output.size()}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["모델 ouput 사이즈: torch.Size([1, 5, 8, 8])\n"]}],"metadata":{"id":"o-pjTeVaS_AP"}},{"cell_type":"code","execution_count":20,"source":["dummy_input = dummy_input.to(cpu_device)\n","model.to(gpu_device)\n","\n","# device is different\n","# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n","output = model(dummy_input)  # 에러 발생\n","print(f\"모델 ouput 사이즈: {output.size()}\")"],"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-92144b071d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# device is different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 에러 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"모델 ouput 사이즈: {output.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-5f680354f5ab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward"]}],"metadata":{"scrolled":true,"id":"aAwqrvnpS_AP"}},{"cell_type":"markdown","source":["### requires_grad()\n"," - autograd 가 해당 모델의 연산을 기록할지를 결정합니다\n"," - false 일 시, 수행하는 연산을 기록하지 않고 따라서 역전파가 되지 않아 학습에서 제외됩니다.\n"," - Change if autograd should record operations on parameters in this module."],"metadata":{"id":"P8ThIO4jS_AQ"}},{"cell_type":"code","execution_count":21,"source":["# requires_grad = False\n","model.requires_grad_(requires_grad=False)\n","for param, weight in model.named_parameters():\n","    print(f\"파라미터 {param:15} 가 gradient 를 tracking 하나요? -> {weight.requires_grad}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["파라미터 conv1.weight    가 gradient 를 tracking 하나요? -> False\n","파라미터 conv1.bias      가 gradient 를 tracking 하나요? -> False\n","파라미터 bn1.weight      가 gradient 를 tracking 하나요? -> False\n","파라미터 bn1.bias        가 gradient 를 tracking 하나요? -> False\n","파라미터 conv2.weight    가 gradient 를 tracking 하나요? -> False\n"]}],"metadata":{"id":"ixAWEZ3iS_AQ"}},{"cell_type":"code","execution_count":22,"source":["# requires_grad = True\n","model.requires_grad_(requires_grad=True)\n","for param, weight in model.named_parameters():\n","    print(f\"파라미터 {param:15} 가 gradient 를 tracking 하나요? -> {weight.requires_grad}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["파라미터 conv1.weight    가 gradient 를 tracking 하나요? -> True\n","파라미터 conv1.bias      가 gradient 를 tracking 하나요? -> True\n","파라미터 bn1.weight      가 gradient 를 tracking 하나요? -> True\n","파라미터 bn1.bias        가 gradient 를 tracking 하나요? -> True\n","파라미터 conv2.weight    가 gradient 를 tracking 하나요? -> True\n"]}],"metadata":{"id":"rysdVfBOS_AR"}},{"cell_type":"markdown","source":["### train(), eval()\n"," - 모델을 training(evaluation) 모드로 전환합니다.\n"," - training 과 evaluation 이 다르게 작용하는 모듈들(Dropout, BatchNorm) 에 영향을 줍니다.\n"," - 학습 단계에서는 training 모드로, 인퍼런스 단계에서는 eval 모드로 전환해주어야 합니다.\n"," - [아래](https://github.com/pytorch/pytorch/blob/1.6/torch/nn/modules/batchnorm.py#L110-L117)는 BatchNorm2d 의 파이토치 구현입니다. `self.training=True` 일 경우에만, `running_mean`, `running_var` 을 tracking 합니다.\n"," \n","```\n","if self.training and self.track_running_stats:\n","    # TODO: if statement only here to tell the jit to skip emitting this when it is None\n","    if self.num_batches_tracked is not None:\n","        self.num_batches_tracked = self.num_batches_tracked + 1\n","        if self.momentum is None:  # use cumulative moving average\n","            exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n","        else:  # use exponential moving average\n","            exponential_average_factor = self.momentum\n","```"],"metadata":{"id":"4oj9DI74S_AR"}},{"cell_type":"code","execution_count":23,"source":["model.train()  # train mode 로 전환\n","print(f\"model.bn1.training: {model.bn1.training}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["model.bn1.training: True\n"]}],"metadata":{"id":"tCxiUYFmS_AS"}},{"cell_type":"code","execution_count":24,"source":["model.eval()  # eval mode 로 전환\n","print(f\"model.bn1.training: {model.bn1.training}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["model.bn1.training: False\n"]}],"metadata":{"id":"NoQ2axpcS_AS"}},{"cell_type":"markdown","source":["### 파이토치 공식 문서에서 nn.Module 에 관한 더 많은 정보를 얻을 수 있습니다.\n","https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n","\n","궁금증이 생기면 공식 문서를 참고하는걸 강력 추천합니다."],"metadata":{"id":"Jvvl6abnS_AS"}}]}