{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"1_EDA.ipynb","provenance":[],"collapsed_sections":["1193ac10-4147-4137-bbf9-60bfed8d61ac","405d624c-368a-49ff-868d-4467831c160d"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"devoted-perry"},"source":["# Lesson 2 - Image Classification & EDA\n","- 2강에서는 데이터를 분석하는 과정인 EDA(Exploratory Data Analysis)에 대해 진행되었습니다. 모델을 설계하는데 있어 데이터를 분석하는 작업은 중요합니다. 이 실습 자료에서는 마스크 데이터셋을 이용하여 간단한 분석 및 시각화를 해봅니다.\n","- 마스크 데이터셋에는 다양한 정보가 존재합니다. 넓은 시야에서 모든 사람의 정보를 수집하여 성별과 연령에 대한 분포를 분석할 수도 있고 이미지 값의 분포를 파악할 수 있습니다. 혹은 개별 이미지를 시각화하여 어떠한 데이터가 있는지 탐색할 수도 있고 마스크의 유무에 따라 이미지가 어떻게 다른지 비교해볼 수도 있겠죠. 이 코드는 단순한 예시이며 이 보다 더 많은 분석을 자유롭게 할 수 있습니다!"],"id":"devoted-perry"},{"cell_type":"markdown","metadata":{"id":"protected-worse"},"source":["## 0. Libraries & Configurations"],"id":"protected-worse"},{"cell_type":"code","metadata":{"id":"direct-dividend"},"source":["import os\n","import sys\n","from glob import glob\n","import numpy as np\n","import pandas as pd\n","import cv2\n","from PIL import Image\n","from tqdm.notebook import tqdm\n","from time import time\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import multiprocessing as mp"],"id":"direct-dividend","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"broke-addiction"},"source":["class cfg:\n","    data_dir = '학습 이미지 폴더의 경로를 입력해주세요.'\n","    img_dir = f'{data_dir}/images'\n","    df_path = f'{data_dir}/train.csv'"],"id":"broke-addiction","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"inside-rabbit"},"source":["num2class = ['incorrect_mask', 'mask1', 'mask2', 'mask3',\n","             'mask4', 'mask5', 'normal']\n","class2num = {k: v for v, k in enumerate(num2class)}\n","\n","df = pd.read_csv(cfg.df_path)\n","df.head()"],"id":"inside-rabbit","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"undefined-romantic"},"source":["## 1. 이미지 RGB정보, 사이즈\n","input이 될 이미지에 대한 분석으로 이미지의 각 채널별 정보, 사이즈, 객체 위치등을 이용하여 이미지의 특성들을 알아봅시다."],"id":"undefined-romantic"},{"cell_type":"markdown","metadata":{"id":"clinical-makeup"},"source":["### 1.1 Dataset Statistics\n","- 여기에선 전체 이미지에 대해서 이미지의 개수와 크기, R, G, B 값의 평균과 표준편차를 계산합니다."],"id":"clinical-makeup"},{"cell_type":"code","metadata":{"id":"recreational-energy"},"source":["def get_ext(img_dir, img_id):\n","    \"\"\"\n","    학습 데이터셋 이미지 폴더에는 여러 하위폴더로 구성되고, 이 하위폴더들에는 각 사람의 사진들이 들어가있습니다. 하위폴더에 속한 이미지의 확장자를 구하는 함수입니다.\n","    \n","    Args:\n","        img_dir: 학습 데이터셋 이미지 폴더 경로 \n","        img_id: 학습 데이터셋 하위폴더 이름\n","\n","    Returns:\n","        ext: 이미지의 확장자\n","    \"\"\"\n","    filename = os.listdir(os.path.join(img_dir, img_id))[0]\n","    ext = os.path.splitext(filename)[-1].lower()\n","    return ext"],"id":"recreational-energy","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"animal-luxury"},"source":["def get_img_stats(img_dir, img_ids):\n","    \"\"\"\n","    데이터셋에 있는 이미지들의 크기와 RGB 평균 및 표준편차를 수집하는 함수입니다.\n","    \n","    Args:\n","        img_dir: 학습 데이터셋 이미지 폴더 경로 \n","        img_ids: 학습 데이터셋 하위폴더 이름들\n","\n","    Returns:\n","        img_info: 이미지들의 정보 (크기, 평균, 표준편차)\n","    \"\"\"\n","    img_info = dict(heights=[], widths=[], means=[], stds=[])\n","    for img_id in tqdm(img_ids):\n","        for path in glob(os.path.join(img_dir, img_id, '*')):\n","            img = np.array(Image.open(path))\n","            h, w, _ = img.shape\n","            img_info['heights'].append(h)\n","            img_info['widths'].append(w)\n","            img_info['means'].append(img.mean(axis=(0,1)))\n","            img_info['stds'].append(img.std(axis=(0,1)))\n","    return img_info"],"id":"animal-luxury","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"widespread-moral"},"source":["img_info = get_img_stats(cfg.img_dir, df.path.values[:100])\n","\n","print(f'Total number of people is {len(df)}')\n","print(f'Total number of images is {len(df) * 7}')\n","\n","print(f'Minimum height for dataset is {np.min(img_info[\"heights\"])}')\n","print(f'Maximum height for dataset is {np.max(img_info[\"heights\"])}')\n","print(f'Average height for dataset is {int(np.mean(img_info[\"heights\"]))}')\n","print(f'Minimum width for dataset is {np.min(img_info[\"widths\"])}')\n","print(f'Maximum width for dataset is {np.max(img_info[\"widths\"])}')\n","print(f'Average width for dataset is {int(np.mean(img_info[\"widths\"]))}')\n","\n","print(f'RGB Mean: {np.mean(img_info[\"means\"], axis=0) / 255.}')\n","print(f'RGB Standard Deviation: {np.mean(img_info[\"stds\"], axis=0) / 255.}')"],"id":"widespread-moral","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"arabic-courage"},"source":["## 1.2 객체의 위치들 확인해보기 \n","- 조금 특수한 분석을 해봅시다. 이 부분은 강의 내용을 벗어나는 코드가 포함되어 있으므로 생략하셔도 괜찮습니다.\n","- 사람 얼굴을 찾는데 딥러닝이 사용되기 이전에, Haar Cascade라는 방법이 많이 사용되었습니다. 이 방법을 이용하여 간단하게 결과를 시각화 해봅시다.\n","- 코드가 제대로 실행이 되지않는다면, opencv에서 제공하는 [haarcascade_frontalface_default.xml](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml)파일을 현재 경로에 받아야합니다."],"id":"arabic-courage"},{"cell_type":"code","metadata":{"id":"unique-valve"},"source":["face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"],"id":"unique-valve","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"talented-drilling"},"source":["imgs = []\n","img_id = df.iloc[500].path\n","ext = get_ext(cfg.img_dir, img_id)\n","for class_id in num2class:\n","    img = np.array(Image.open(os.path.join(cfg.img_dir, img_id, class_id+ext)))\n","    imgs.append(img)\n","imgs = np.array(imgs)"],"id":"talented-drilling","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"electrical-accent"},"source":["fig, axes = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(12, 6))\n","axes[0].imshow(imgs[0])\n","axes[1].imshow(imgs[1])\n","axes[2].imshow(imgs[-1])\n","plt.show()"],"id":"electrical-accent","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"compressed-belfast"},"source":["### 2. target값 y에 대한 분석\n","저희가 맞춰야하는 정보들이 어떤 것인지 확인해보고 어떤 분포를 갖고 있는지 확인해봅시다."],"id":"compressed-belfast"},{"cell_type":"markdown","metadata":{"id":"naval-blanket"},"source":["- 여기에선 train.csv에 저장되어있는 메타 데이터를 분석합니다. seaborn 시각화 라이브러리를 통해 성별의 분포와 연령 분포를 확인해봅시다."],"id":"naval-blanket"},{"cell_type":"markdown","metadata":{"id":"351920f5-2fdf-4c10-b062-40545aad5b96"},"source":["### 2.1 y값 독립적 분포 확인"],"id":"351920f5-2fdf-4c10-b062-40545aad5b96"},{"cell_type":"code","metadata":{"id":"dense-techno"},"source":["plt.figure(figsize=(6, 4.5)) \n","ax = sns.countplot(x = 'gender', data = df, palette=[\"#55967e\", \"#263959\"])\n","\n","plt.xticks( np.arange(2), ['female', 'male'] )\n","plt.title('Sex Ratio',fontsize= 14)\n","plt.xlabel('')\n","plt.ylabel('Number of images')\n","\n","counts = df['gender'].value_counts()\n","counts_pct = [f'{elem * 100:.2f}%' for elem in counts / counts.sum()]\n","for i, v in enumerate(counts_pct):\n","    ax.text(i, 0, v, horizontalalignment = 'center', size = 14, color = 'w', fontweight = 'bold')\n","    \n","plt.show()"],"id":"dense-techno","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d60b4495-93d5-4ba9-99a4-0c06229a060c"},"source":["sns.displot(df, x=\"age\", stat=\"density\")\n","plt.show()"],"id":"d60b4495-93d5-4ba9-99a4-0c06229a060c","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"85a1111e-af14-4387-843e-3be9b5c78ca0"},"source":["### 2.2 y값들 간의 관계 분포\n","- 나이와 성별에 따른 분포는 어떻게 구성되었는지 알아봅시다."],"id":"85a1111e-af14-4387-843e-3be9b5c78ca0"},{"cell_type":"code","metadata":{"id":"breathing-sunset"},"source":["sns.displot(df, x=\"age\", hue=\"gender\", stat=\"density\")\n","plt.show()"],"id":"breathing-sunset","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0d4b9584-e33c-446d-bd3b-1ca97cdad6d1"},"source":["df['age'].describe()"],"id":"0d4b9584-e33c-446d-bd3b-1ca97cdad6d1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"de38b801-be59-4ba6-b39e-b8345378ae6d"},"source":["sns.boxplot(x='gender', y='age', data=df)\n","plt.show()"],"id":"de38b801-be59-4ba6-b39e-b8345378ae6d","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c8fde83b-c054-414e-8430-048768e370e7"},"source":["- 남성과 여성의 나이의 범위는 같지만 경향성은 다른 것을 확인할 수 있습니다."],"id":"c8fde83b-c054-414e-8430-048768e370e7"},{"cell_type":"markdown","metadata":{"id":"0ba692d2-9901-4cc8-b232-a435a928b3e6"},"source":["- 데이터들의 불균형(data imbalance)가 심해보이네요 이를 위해서는 어떤 분석방법을 사용해야할까요??"],"id":"0ba692d2-9901-4cc8-b232-a435a928b3e6"},{"cell_type":"markdown","metadata":{"id":"1193ac10-4147-4137-bbf9-60bfed8d61ac"},"source":["### 3. X, y 관계확인\n","X인 이미지와 y의 관계는 어떤 것이 있을까요??\n","- 분석하고자 하는 이미지와 y의 관계를 알게된다면 전처리, data augmentation 혹은 CNN의 구조를 풀고자하는 문제에 적합하게 적용해볼 수 있습니다."],"id":"1193ac10-4147-4137-bbf9-60bfed8d61ac"},{"cell_type":"markdown","metadata":{"id":"405d624c-368a-49ff-868d-4467831c160d"},"source":["### 3.1 이미지 사이즈와 y값의 관계\n","- image size는 모두 같은 사이즈라 y값과 관계가 없습니다."],"id":"405d624c-368a-49ff-868d-4467831c160d"},{"cell_type":"markdown","metadata":{"id":"f87baa4b-816c-4488-a819-5cd490e922af"},"source":["### 3.2 이미지 RGB 통계값과 y 특성의 관계"],"id":"f87baa4b-816c-4488-a819-5cd490e922af"},{"cell_type":"code","metadata":{"id":"48c640ea-af60-4753-a140-f7a77d618356"},"source":["img_id = df.iloc[500].path\n","ext = get_ext(cfg.img_dir, img_id)"],"id":"48c640ea-af60-4753-a140-f7a77d618356","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdef002e-7973-432b-a74b-55a907d112c6"},"source":["plt.figure()\n","plt.subplot(111)\n","\n","for class_id in num2class:\n","    img = np.array(Image.open(os.path.join(cfg.img_dir, img_id, class_id+ext)).convert('L'))\n","    histogram, bin_edges = np.histogram(img, bins=256, range=(0, 255))\n","    sns.lineplot(data=histogram)\n","\n","plt.legend(num2class)\n","plt.title('Class Grayscale Histogram Plot', fontsize=15)\n","plt.show()"],"id":"cdef002e-7973-432b-a74b-55a907d112c6","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"employed-projection"},"source":["- 마스크의 종류가 5개라 plot이 산만한 것같으니 마스크는 평균을 취해서 확인해봅시다."],"id":"employed-projection"},{"cell_type":"code","metadata":{"id":"a0f778f3-62d5-437b-9afe-e098dbd47990"},"source":["plt.figure()\n","plt.subplot(111)\n","\n","img = np.array(Image.open(os.path.join(cfg.img_dir, img_id, 'incorrect_mask'+ext)).convert('L'))\n","histogram, bin_edges = np.histogram(img, bins=256, range=(0, 255))\n","sns.lineplot(data=histogram)\n","\n","img = np.array(Image.open(os.path.join(cfg.img_dir, img_id, 'normal'+ext)).convert('L'))\n","histogram, bin_edges = np.histogram(img, bins=256, range=(0, 255))\n","sns.lineplot(data=histogram, color='hotpink')\n","\n","histograms = []\n","for i in range(1, 6):\n","    img = np.array(Image.open(os.path.join(cfg.img_dir, img_id, num2class[i]+ext)).convert('L'))\n","    histogram, bin_edges = np.histogram(img, bins=256, range=(0, 255))\n","    histograms.append(histogram)\n","sns.lineplot(data=np.mean(histograms, axis=0))\n","\n","plt.legend(['incorrect_mask', 'normal', 'mask average'])\n","plt.title('Class Grayscale Histogram Plot', fontsize=15)\n","plt.show()"],"id":"a0f778f3-62d5-437b-9afe-e098dbd47990","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"alert-aerospace"},"source":["- 마스크를 쓰지않은 사진의 RGB 분포도 살펴볼까요?"],"id":"alert-aerospace"},{"cell_type":"code","metadata":{"id":"suburban-battery"},"source":["plt.figure()\n","plt.subplot(111)\n","\n","img = np.array(Image.open(os.path.join(cfg.img_dir, img_id, 'normal'+ext)))\n","colormap = ['red', 'green', 'blue']\n","for i in range(3):\n","    histogram, bin_edges = np.histogram(img[..., i], bins=256, range=(0, 255))\n","    sns.lineplot(data=histogram, color=colormap[i])\n","\n","plt.legend()\n","plt.title('RGB Histogram Plot - Normal', fontsize=15)\n","plt.show()"],"id":"suburban-battery","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1fce8a80-73cc-44ee-a2b4-c40c9e08ccf8"},"source":["### 3.3 객체의 위치와 y의 관계\n","객체의 위치와 y의 관계를 찾는 방법은 직접 다 확인하는 방법이 있을 수도 있지만 위에서 사용한 face detection을 이용하여 box의 위치들의 통계값들을 이용하여 찾을 수 있을 것 같습니다."],"id":"1fce8a80-73cc-44ee-a2b4-c40c9e08ccf8"},{"cell_type":"markdown","metadata":{"id":"adf2060e-f5bf-474c-8f70-78dc908e59cc"},"source":["- 이미지 별로 통계값을 뽑아내는 것은 캠퍼님들이 직접 해보시면 좋을 것 같습니다."],"id":"adf2060e-f5bf-474c-8f70-78dc908e59cc"},{"cell_type":"markdown","metadata":{"id":"c4ba3812-e0eb-48aa-8566-66608c492678"},"source":["\n","- 아래 코드는 어떤 label이 얼굴을 잘찾지 못하는지 확인해봅시다."],"id":"c4ba3812-e0eb-48aa-8566-66608c492678"},{"cell_type":"code","metadata":{"id":"92d703b0-8cbe-457d-83ed-72998cea6133"},"source":["face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"],"id":"92d703b0-8cbe-457d-83ed-72998cea6133","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ddb69e6-ad5b-4cfa-a3a8-df69269e906a"},"source":["imgs = []\n","bboxes = []\n","not_found_idx = []\n","img_id = df.iloc[504].path\n","ext = get_ext(cfg.img_dir, img_id)\n","for i, class_id in enumerate(num2class):\n","    img = np.array(Image.open(os.path.join(cfg.img_dir, img_id, class_id+ext)))\n","    bbox = face_cascade.detectMultiScale(img)\n","    imgs.append(img)\n","    if len(bbox) != 0:\n","        bboxes.append(bbox.max(axis=0))\n","    else:\n","        not_found_idx.append(i)\n","        print(f'{class_id} not found face')\n","imgs = np.array(imgs)\n","bboxes = np.array(bboxes)"],"id":"5ddb69e6-ad5b-4cfa-a3a8-df69269e906a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"da6e40c0-68f4-4bd4-b8dd-7d5592422b55"},"source":["fig, axes = plt.subplots(1, len(not_found_idx), sharex=True, sharey=True, figsize=(12, 6))\n","for i, j in enumerate(range(len(not_found_idx))):\n","    axes[i].imshow(imgs[j])\n","    axes[i].set_title(f'{num2class[j]}')\n","plt.show()"],"id":"da6e40c0-68f4-4bd4-b8dd-7d5592422b55","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"465d243b-436b-4be3-b936-d5e7bc50d7c0"},"source":["- 대부분의 이미지들은 인물들이 정중앙에 있는 것으로 확인\n","- mask5는 대부분 bbox를 찾지 못함\n","- 가끔 mask1도 찾지 못함"],"id":"465d243b-436b-4be3-b936-d5e7bc50d7c0"},{"cell_type":"markdown","metadata":{"id":"split-webster"},"source":["### 3.4 데이터 노이즈 확인\n","- 사람마다 총 7장의 사진이 존재합니다. (마스크 정상 착용 5장, 미착용 1장, 이상하게 착용 1장).\n","- 이 파트에서는 이미지를 직접 시각화하여 눈으로 관찰하여 label에 문제가 없는지 확인해봅시다. \n"],"id":"split-webster"},{"cell_type":"markdown","metadata":{"id":"b3ea35f0-068c-4f88-821c-963329d2bf7b"},"source":["한 사람의 데이터를 시각화해봅시다."],"id":"b3ea35f0-068c-4f88-821c-963329d2bf7b"},{"cell_type":"code","metadata":{"id":"aboriginal-teens"},"source":["def plot_raw_images(img_dir, img_id):\n","    \"\"\"\n","    마스크 미착용 이미지를 시각화하는 함수입니다.\n","    \n","    Args:\n","        img_dir: 학습 데이터셋 이미지 폴더 경로 \n","        img_id: 학습 데이터셋 하위폴더 이름\n","    \"\"\"\n","    ext = get_ext(img_dir, img_id)\n","    img = np.array(Image.open(os.path.join(img_dir, img_id, 'normal' + ext)))\n","    \n","    plt.figure(figsize=(6,6))\n","    plt.imshow(img)\n"],"id":"aboriginal-teens","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e4fccf4b-3e32-4c63-980d-ff2f1451d4f7"},"source":["def show_from_id(idx):\n","    img_id = df.iloc[idx].path\n","    gen = df.iloc[idx].gender\n","    age = df.iloc[idx].age\n","    plot_raw_images(cfg.img_dir, img_id)\n","    plt.title(f'{gen} {age}')\n","    plt.show()\n"],"id":"e4fccf4b-3e32-4c63-980d-ff2f1451d4f7","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2c33131b-baa1-452d-a380-0dda75e63c46"},"source":["- 남성으로 보이지만 여성으로 표시되어 있는경우"],"id":"2c33131b-baa1-452d-a380-0dda75e63c46"},{"cell_type":"code","metadata":{"id":"062b1143-8e6c-4bdf-9206-af57f622057f"},"source":["show_from_id(2399)"],"id":"062b1143-8e6c-4bdf-9206-af57f622057f","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2370a95c-6a01-46fa-9b75-6848bac52e22"},"source":["show_from_id(2400)"],"id":"2370a95c-6a01-46fa-9b75-6848bac52e22","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cdc75a34-e8ab-466d-aa19-d558cbcb3199"},"source":["- 여성으로 보이지만 남성으로 표시되어 있는 경우"],"id":"cdc75a34-e8ab-466d-aa19-d558cbcb3199"},{"cell_type":"code","metadata":{"id":"compound-castle"},"source":["show_from_id(1912)"],"id":"compound-castle","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"40b56c5a-f587-431d-9ed8-934ef473b943"},"source":["show_from_id(764)"],"id":"40b56c5a-f587-431d-9ed8-934ef473b943","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b268811c-96b0-42ac-b5e3-baf6be007613"},"source":["꾀 많은 경우로 데이터의 경향성을 방해하는 데이터가 있는 것으로 확인됩니다. \n","\n","이를 위해서는 어떤 방법을 이용하는 것이 좋을까요???"],"id":"b268811c-96b0-42ac-b5e3-baf6be007613"},{"cell_type":"markdown","metadata":{"id":"fd47d45d-2353-403b-a39f-6c01dd1f0313"},"source":["- id 별로 마스크 착용 상태를 확인해봅시다."],"id":"fd47d45d-2353-403b-a39f-6c01dd1f0313"},{"cell_type":"code","metadata":{"id":"disabled-opposition"},"source":["def plot_mask_images(img_dir, img_id):\n","    \"\"\"\n","    마스크 정상착용 5장과 이상하게 착용한 1장을 2x3의 격자에 시각화하는 함수입니다.\n","    \n","    Args:\n","        img_dir: 학습 데이터셋 이미지 폴더 경로 \n","        img_id: 학습 데이터셋 하위폴더 이름\n","    \"\"\"\n","    ext = get_ext(img_dir, img_id)\n","    imgs = [np.array(Image.open(os.path.join(img_dir, img_id, class_name + ext))) for class_name in num2class[:-1]]\n","    \n","    n_rows, n_cols = 2, 3\n","    fig, axes = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, figsize=(15, 12))\n","    for i in range(n_rows*n_cols):\n","        axes[i//(n_rows+1)][i%n_cols].imshow(imgs[i])\n","        axes[i//(n_rows+1)][i%n_cols].set_title(f'{num2class[i]}', color='r')\n","    plt.tight_layout()\n","    plt.show()"],"id":"disabled-opposition","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"loving-sport"},"source":["idx = 500\n","img_id = df.iloc[idx].path\n","plot_mask_images(cfg.img_dir, img_id)"],"id":"loving-sport","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"manual-briefing"},"source":["### (Optional) PCA\n","- 주성분 분석은 이미지 데이터 분포의 주성분을 구하는 방법입니다.\n","- 300 장의 얼굴 이미지에 대한 주성분 벡터(eigenface)를 구하고 T-SNE를 통해 차원축소를 하여 각 클래스마다의 분포차이를 시각화해봅시다."],"id":"manual-briefing"},{"cell_type":"code","metadata":{"id":"polar-scheme"},"source":["from sklearn.manifold import TSNE\n","from sklearn.decomposition import PCA"],"id":"polar-scheme","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dated-logging"},"source":["n_imgs = 100\n","\n","imgs = []\n","for img_id in df.path.values[:n_imgs]:\n","    for class_id in num2class:\n","        img = np.array(Image.open(os.path.join(cfg.img_dir, img_id, class_id+ext)).convert('L'))\n","        imgs.append(img)\n","imgs = np.array(imgs)\n","n_samples, h, w = imgs.shape\n","\n","imgs = np.reshape(imgs, (n_samples, h*w))"],"id":"dated-logging","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"involved-tumor"},"source":["n_components = 30\n","\n","t0 = time()\n","pca = PCA(n_components=n_components, svd_solver='randomized',\n","          whiten=True).fit(imgs)\n","print(f\"pca is fitted in {time() - t0:.0f}s\")\n","print(f'Explained variation per principal component: \\n{pca.explained_variance_ratio_}')\n","\n","eigenfaces = pca.components_.reshape((n_components, h, w))\n","img_pca = pca.transform(imgs)"],"id":"involved-tumor","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"applied-teens"},"source":["pca_df = pd.DataFrame(img_pca, columns=[str(col) for col in range(n_components)])\n","pca_df['class_id'] = [num2class[n % len(num2class)] for n in range(n_samples)]\n","pca_df['class_id'] = pca_df['class_id'].map(lambda x: x if x in ['incorrect_mask', 'normal'] else 'mask')"],"id":"applied-teens","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oriented-cooler"},"source":["pca_df.head()"],"id":"oriented-cooler","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"needed-sellers"},"source":["plt.figure(figsize=(8,6))\n","sns.scatterplot(\n","    x='0', y='1',\n","    hue=\"class_id\",\n","    data=pca_df,\n","    legend=\"full\",\n","    palette=sns.color_palette(\"Set2\", 3),\n","    alpha=0.8\n",")\n","plt.show()"],"id":"needed-sellers","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"senior-group"},"source":["ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n","simplified_num2class = ['incorrect_mask', 'mask', 'normal']\n","simplified_class2num = {k: v for v, k in enumerate(simplified_num2class)}\n","ax.scatter(\n","    xs=pca_df[\"0\"], \n","    ys=pca_df[\"1\"], \n","    zs=pca_df[\"2\"], \n","    c=pca_df['class_id'].map(lambda x: simplified_class2num[x]), \n",")\n","ax.set_xlabel('pc1')\n","ax.set_ylabel('pc2')\n","ax.set_zlabel('pc3')\n","\n","plt.legend(simplified_num2class)\n","plt.show()"],"id":"senior-group","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"purple-electronics"},"source":["time_start = time()\n","tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n","tsne_results = tsne.fit_transform(img_pca)\n","print('t-SNE done! Time elapsed: {} seconds'.format(time()-time_start))"],"id":"purple-electronics","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"minimal-brake"},"source":["pca_df['tsne-2d-one'] = tsne_results[:,0]\n","pca_df['tsne-2d-two'] = tsne_results[:,1]\n","plt.figure(figsize=(8,6))\n","sns.scatterplot(\n","    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n","    hue=\"class_id\",\n","    palette=sns.color_palette(\"Set2\", 3),\n","    data=pca_df,\n","    legend=\"full\",\n","    alpha=0.8\n",")\n","plt.show()"],"id":"minimal-brake","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"civil-increase"},"source":["## 4. Reference"],"id":"civil-increase"},{"cell_type":"markdown","metadata":{"id":"canadian-camping"},"source":["- [Visualising high-dimensional datasets using PCA and t-SNE in Python](https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b)\n","- [Faces recognition example using eigenfaces and SVMs](https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html)\n","- [Seaborn docs](https://seaborn.pydata.org/index.html)\n","- [Face Detection in 2 Minutes using OpenCV & Python](https://towardsdatascience.com/face-detection-in-2-minutes-using-opencv-python-90f89d7c0f81)"],"id":"canadian-camping"}]}